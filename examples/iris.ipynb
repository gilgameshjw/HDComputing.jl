{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module HDSparse.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "getNextNodes (generic function with 1 method)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLJ\n",
    "using MLJModels, Statistics, PrettyPrinting\n",
    "using ProgressMeter\n",
    "\n",
    "include(\"src/modelHDSparse.jl\")\n",
    "include(\"src/libEncoding.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mActivating\u001b[22m\u001b[39m environment at `~/WORK/MLJ/HDComputing.jl/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg; Pkg.activate(\".\"); Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparse2Dense (generic function with 1 method)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "irisKeys = X |> keys |> collect\n",
    "\n",
    "# data to dictionary\n",
    "getData = i -> map(k -> string(k) => X[k][i], irisKeys) |> \n",
    "                    Dict\n",
    "\n",
    "\n",
    "# coarse coding\n",
    "function mapPos2Indices(x, xMin, xMax, nGridlat) # approximation on the top left of grid\n",
    "    ceil(nGridlat * (x - xMin) / (xMax - xMin)) |> Int64\n",
    "end\n",
    "\n",
    "\n",
    "# embedding with neighbours in \"manifold?\"\n",
    "getCoarseEvent = (x, feat, fMin, fMax, gridResolution, gridNb) -> \n",
    "                    map(i -> x + i*((fMax - fMin) / gridResolution), -gridNb:gridNb) |>\n",
    "                        (A -> map(x -> mapPos2Indices(x, fMin, fMax, gridResolution), A)) |>\n",
    "                            (A -> feat => map(a -> string(a), A))\n",
    "\n",
    "\n",
    "function dataModel(dD)\n",
    "    vcat(\n",
    "         map(d -> (feat = Symbol(d[1]);\n",
    "                   x = d[2];\n",
    "                   fMin = dicBoundaries[feat][:min];\n",
    "                   fMax = dicBoundaries[feat][:max];\n",
    "                   getCoarseEvent(x, feat, fMin, fMax, nGridResolution, gridNb)),\n",
    "             collect(dD))\n",
    "         ...)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "##### Data is continuous so we embedd it within a scheme approximating distance or similiarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = @load_iris;\n",
    "\n",
    "data = [getData(i) for i=1:length(X.petal_length)]\n",
    "\n",
    "\n",
    "dicBoundaries = map(k -> k => Dict(:max => maximum(X[k]), :min => minimum(X[k])), collect(keys(X))) |>\n",
    "                    Dict;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparse2Dense (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "include(\"../src/modelHDSparse.jl\")\n",
    "\n",
    "n = 100000\n",
    "\n",
    "# We build SDRs dictionary \"as you go\"\n",
    "dicSDMs = Dict()\n",
    "\n",
    "wTxt, wTag, wTarget = 1, 1, 13 \n",
    "\n",
    "dicModelEncoding = Dict(:sepal_length => Dict(:N => n, :W => 1),\n",
    "                        :petal_width => Dict(:N => n, :W => 1),\n",
    "                        :petal_length => Dict(:N => n, :W => 1),\n",
    "                        :sepal_width => Dict(:N => n, :W => 1))\n",
    "\n",
    "\n",
    "function encoderHD(dicSDMs,\n",
    "                   dicModelEncoding::Dict{Symbol,Dict{Symbol,Int64}},\n",
    "                   dicData::Array{Pair{Symbol,Array{String,1}},1})\n",
    "     [(k = kv[1];\n",
    "       ws = kv[2];\n",
    "       vcat(map(w -> HDSparse.encodeOnTheFly(dicSDMs, dicModelEncoding[k], string(k, \"_\", w)), ws)...))\n",
    "      for kv in dicData] |>\n",
    "                HDSparse.superposition\n",
    "end\n",
    "\n",
    "\n",
    "function sparse2Dense(sparseVec)\n",
    "    \"\"\"\n",
    "        Utility to convert into classifiable format.\n",
    "    \"\"\"\n",
    "    v = zeros(n)\n",
    "    for i in sparseVec.nzind\n",
    "         v[i] = 1\n",
    "    end\n",
    "    v\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "vv = data[1] |> dataModel\n",
    "dataSDM = @showprogress map(d -> encoderHD(dicSDMs, dicModelEncoding, d |> dataModel) |>\n",
    "                                    sparse2Dense, data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epic fail with MLJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The scitype of `X`, in `machine(model, X, y)` or \n",
      "└ @ MLJ /root/.julia/packages/MLJ/LDDzK/src/machines.jl:54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @ 3…33\u001b[39m\n"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load DecisionTreeClassifier\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree = machine(tree_model, dataSDM, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @ 3…33\u001b[39m.\n",
      "└ @ MLJ /root/.julia/packages/MLJ/LDDzK/src/machines.jl:172\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: ",
     "output_type": "error",
     "traceback": [
      "ArgumentError: ",
      "",
      "Stacktrace:",
      " [1] #matrix#23(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(MLJBase.matrix), ::Val{:other}, ::Array{Array{Float64,1},1}) at /root/.julia/packages/MLJBase/JdmO3/src/data.jl:342",
      " [2] matrix(::Val{:other}, ::Array{Array{Float64,1},1}) at /root/.julia/packages/MLJBase/JdmO3/src/data.jl:342",
      " [3] #matrix#22(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(MLJBase.matrix), ::Array{Array{Float64,1},1}) at /root/.julia/packages/MLJBase/JdmO3/src/data.jl:341",
      " [4] matrix at /root/.julia/packages/MLJBase/JdmO3/src/data.jl:341 [inlined]",
      " [5] fit(::DecisionTreeClassifier, ::Int64, ::Array{Array{Float64,1},1}, ::CategoricalArrays.CategoricalArray{String,1,UInt8,String,CategoricalArrays.CategoricalString{UInt8},Union{}}) at /root/.julia/packages/MLJModels/ayF3A/src/DecisionTree.jl:92",
      " [6] #fit!#4(::Array{Int64,1}, ::Int64, ::Bool, ::typeof(fit!), ::Machine{DecisionTreeClassifier}) at /root/.julia/packages/MLJ/LDDzK/src/machines.jl:173",
      " [7] (::StatsBase.var\"#kw##fit!\")(::NamedTuple{(:rows,),Tuple{Array{Int64,1}}}, ::typeof(fit!), ::Machine{DecisionTreeClassifier}) at ./none:0",
      " [8] top-level scope at In[139]:2"
     ]
    }
   ],
   "source": [
    "train, test = partition(eachindex(y), 0.7, shuffle=true)\n",
    "fit!(tree, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0-rc4",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
