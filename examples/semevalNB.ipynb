{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/packages/Conda/CpuvI/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m PyCall → `~/.julia/packages/PyCall/0jMpb/deps/build.log`\n"
     ]
    }
   ],
   "source": [
    "ENV[\"PYTHON\"] = \"/home/jair/anaconda3/envs/py36/bin/python\"\n",
    "using Pkg\n",
    "Pkg.build(\"PyCall\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using StatsBase\n",
    "\n",
    "using ScikitLearn\n",
    "@pyimport sklearn.datasets as datasets\n",
    "@pyimport sklearn.naive_bayes as NB\n",
    "@pyimport sklearn.tree as Tree\n",
    "@pyimport sklearn.linear_model as LM\n",
    "@pyimport sklearn.ensemble as E\n",
    "@pyimport sklearn.svm as SVM\n",
    "\n",
    "@pyimport sklearn.metrics as METRICS\n",
    "\n",
    "@pyimport nltk.stem as NLTK_STEM\n",
    "@pyimport nltk.corpus as NLTK_CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#===========================\n",
    "    Load files\n",
    "===========================#\n",
    "\n",
    "path = \"/home/jair/Desktop/FACTMATA/\"\n",
    "fileTrain = \"trainA.csv\"\n",
    "fileTest = \"testA.csv\"\n",
    "\n",
    "dfTrain = CSV.read( string(path, fileTrain))\n",
    "names!(dfTrain, [:ID,:Tweet, :Target, :Stance, :OpinionsTowards, :Sentiment])\n",
    "dfTest = CSV.read(string(path, fileTest))\n",
    "names!(dfTest, [:ID1,:ID2, :Target,:Tweet, :Stance])\n",
    "dfTest[:Sentiment] = map(i -> i, 1:size(dfTest, 1))\n",
    "dfTest[:OpinionsTowards] = map(i -> i, 1:size(dfTest, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#===========================\n",
    "    NLP from scratch\n",
    "============================#\n",
    "\n",
    "stopWords = NLTK_CORPUS.stopwords[:words](\"english\")\n",
    "filterWords = vcat([\"\"], stopWords)\n",
    "\n",
    "stemmer = NLTK_STEM.SnowballStemmer(\"english\")\n",
    "\n",
    "function largestSentenceOnly(corpus)\n",
    "    maxCorpus = maximum(map(c -> length(c), corpus))\n",
    "    for c in corpus\n",
    "        if length(c) == maxCorpus\n",
    "            return c\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function parseTxt2BoW(text)\n",
    "    # 1. decompose into sentences\n",
    "    # 2. sentences -> Nag of Words\n",
    "    \n",
    "    function lowerCase(wrd)\n",
    "       try\n",
    "            lowercase(wrd) |> \n",
    "                (W -> filter(s -> !(s in ['\\\"']), W)) |>  # , '-', '+', '~'\n",
    "                stemmer[:stem]\n",
    "        catch # found strange characters in dataset, maybe emoticons? '\\x90','\\xa2','\\xb4','\\xa0','\\xb4','\\xd3'\n",
    "            wrd\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    function massageText(wrds)\n",
    "        # filter words\n",
    "        wrds = filter(w -> !(w in filterWords), wrds)\n",
    "        # filter words with symbols\n",
    "        filter(w -> true, wrds) |> # !(w[1] in ['#', '@']), wrds)\n",
    "            (W -> map(w -> lowerCase(w), W))\n",
    "    end\n",
    "    \n",
    "    \n",
    "    split(text, ['.','!','?']) |> \n",
    "        (txt -> map(t -> (split(t, [' ',',','/','\\'',';',':',]) |> massageText), \n",
    "                    txt)) |> #largestSentenceOnly |>\n",
    "        (T -> vcat(T...)) |>\n",
    "        (T -> filter(x -> x != \"\", T))\n",
    "end\n",
    "\n",
    "\n",
    "#===\n",
    "    Test parser on real tweets\n",
    "===#\n",
    "\n",
    "for (i,t) in enumerate(vcat(dfTrain[:Tweet])\n",
    "    try\n",
    "        parseTxt2BoW(t)\n",
    "    catch\n",
    "        println(\"bug in train: \", i)\n",
    "    end\n",
    "end\n",
    "\n",
    "for (i,t) in enumerate(dfTest[:Tweet])\n",
    "    try\n",
    "        parseTxt2BoW(t)\n",
    "    catch\n",
    "        println(\"bug in test: \", i)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#===\n",
    "    Used to fined tuned the SDR model\n",
    "===#\n",
    "\n",
    "lengthsTrain = map(t -> length(vcat(parseTxt2BoW(t)...)), dfTrain[:Tweet])  \n",
    "lengthsTest = map(t -> length(vcat(parseTxt2BoW(t)...)), dfTest[:Tweet])\n",
    "using PyPlot\n",
    "xlabel(\"# of words/tags\")\n",
    "ylabel(\"# of counts\")\n",
    "hist(lengthsTrain)\n",
    "hist(lengthsTest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=====================\n",
    "    SDRs model 0.1\n",
    "======================#\n",
    "\n",
    "using SparseArrays\n",
    "\n",
    "function RandomIndexGenerator(n, w)\n",
    "    # generates random vector of form [0 0 0 ... 0 1 0 ... 0 0 0 0 0 0 1 0 0 0 0 ...]\n",
    "    ...\n",
    "end\n",
    "\n",
    "# std cosine sim\n",
    "function standardCosineSimilarity(v1, v2)\n",
    "    v2' * v2 / ((v1' * v1) * (v2' * v2))^.5\n",
    "end\n",
    "\n",
    "function sparseCosineSimilarity(ri1, ri2)\n",
    "\n",
    "    sparseVectorMultiplication(ri1, ri2) = \n",
    "        ...\n",
    "\n",
    "    sparseVectorMultiplication(ri1, ri2) / \n",
    "        (length(ri2.nzval) * length(ri2.nzval))^.5\n",
    "    end\n",
    "\n",
    "\n",
    "#================\n",
    "# Data Model 0.1\n",
    "=================#\n",
    "\n",
    "# length of sdrs\n",
    "n = 10000\n",
    "\n",
    "# cardinals (for text and tag)\n",
    "# numbers are tweaked so vectors remain sparse after composition\n",
    "wTxt, wTag, wTarget = 1, 1, 13 # 5, 10, 5\n",
    "\n",
    "# \"encoding model\"\n",
    "fields = [:Tweet, :Target]\n",
    "dicWeights = Dict(:Tweet => wTxt, :Target => wTarget)\n",
    "\n",
    "# Map data into random vector via simple compositions/additions\n",
    "function dataRow2SDR(dfRow)\n",
    "    idces = []\n",
    "    target = dfRow[:Target]\n",
    "    ...\n",
    "    \n",
    "    txtBoW = vcat(parseTxt2BoW(dfRow[:Tweet])...)\n",
    "    \n",
    "    biGrams = [string(\"_BI_\", string(sort([txtBoW[i],txtBoW[i-1]]))) for i=2:length(txtBoW)]\n",
    "    \n",
    "    biGramsSkip1 = [string(\"_BI_SKIP1_\", string(sort([txtBoW[i],txtBoW[i-2]]))) for i=3:length(txtBoW)]\n",
    "    \n",
    "    triGrams = [string(\"_TRI_\", string(sort([txtBoW[i],txtBoW[i-1], txtBoW[2-1]]))) for i=3:length(txtBoW)]\n",
    "    \n",
    "    for wrd in txtBoW # vcat(txtBoW,  biGrams, biGramsSkip1, triGrams) \n",
    "        ...\n",
    "    end\n",
    "    \n",
    "    ...\n",
    "    sparsevec(idces, 1:length(idces))\n",
    "end\n",
    "\n",
    "# We build SDRs dictionary \"as you go\"\n",
    "dicSDRs = Dict()\n",
    "\n",
    "function encodeOnTheFly(wrdOrTag, dictSDRs, w)\n",
    "    if haskey(dictSDRs, wrdOrTag)\n",
    "        dictSDRs[wrdOrTag].nzind\n",
    "    else\n",
    "        randSDR = RandomIndexGenerator(n, w)\n",
    "        dictSDRs[wrdOrTag] = randSDR\n",
    "        randSDR.nzind\n",
    "    end\n",
    "end\n",
    "\n",
    "function sparse2Dense(sparseVec)\n",
    "    v = zeros(n)\n",
    "    for i in sparseVec.nzind\n",
    "         v[i] = 1\n",
    "    end\n",
    "    v\n",
    "end\n",
    "\n",
    "\n",
    "function getF1Scores(yTest, yClassified)\n",
    "    #===\n",
    "        fmacroT and fmicroT for \"main classes\"\n",
    "    ===#    \n",
    "    f1Macro = METRICS.f1_score(yTest, yClassified, average=\"macro\")\n",
    "    f1Micro = METRICS.f1_score(yTest, yClassified, average=\"micro\")\n",
    "    \n",
    "    idcesFavor = filter(i -> yTest[i] == classes[\"FAVOR\"], 1:length(yTest)) \n",
    "    idcesAgainst = filter(i -> yTest[i] == classes[\"AGAINST\"], 1:length(yTest))\n",
    "    idcesNone = filter(i -> yTest[i] == classes[\"NONE\"], 1:length(yTest))\n",
    "    \n",
    "    fFavorMacro = METRICS.f1_score(map(i -> yTest[i], idcesFavor), \n",
    "                                   map(i -> yClassified[i], idcesFavor), average=\"macro\")\n",
    "    fAgainstMacro = METRICS.f1_score(map(i -> yTest[i], idcesAgainst),\n",
    "                                     map(i -> yClassified[i], idcesAgainst), average=\"macro\")\n",
    "    fNoneMacro = METRICS.f1_score(map(i -> yTest[i], idcesNone),\n",
    "                                  map(i -> yClassified[i], idcesNone), average=\"macro\")\n",
    "    \n",
    "    fFavorMicro = METRICS.f1_score(map(i -> yTest[i], idcesFavor),\n",
    "                                   map(i -> yClassified[i], idcesFavor), average=\"micro\")\n",
    "    fAgainstMicro = METRICS.f1_score(map(i -> yTest[i], idcesAgainst),\n",
    "                                     map(i -> yClassified[i], idcesAgainst), average=\"micro\")\n",
    "    fNoneMicro = METRICS.f1_score(map(i -> yTest[i], idcesNone),\n",
    "                                  map(i -> yClassified[i], idcesNone), average=\"micro\")\n",
    "\n",
    "    Dict(:fMacro => (fFavorMacro + fAgainstMacro) / 2,\n",
    "         :fMicro => (fFavorMicro + fAgainstMicro) / 2,\n",
    "         :fMacroT => (fFavorMacro + fAgainstMacro + fNoneMacro) / 3,\n",
    "         :fMicroT => (fFavorMicro + fAgainstMicro + fNoneMicro) / 3)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "avg lgth: 24.221002059025395\n",
      "0.6477181745396317\n",
      "0.44469372435474125\n",
      "Dict(:fMacro=>0.346506,:fMicro=>0.69649,:fMicroT=>0.471573,:fMacroT=>0.235732)\n",
      "2\n",
      "avg lgth: 24.215168153740564\n",
      "0.6461168935148118\n",
      "0.4431005292659438\n",
      "Dict(:fMacro=>0.345807,:fMicro=>0.694146,:fMicroT=>0.47001,:fMacroT=>0.235266)\n",
      "3\n",
      "avg lgth: 24.216540837336993\n",
      "0.644515612489992\n",
      "0.4415539867519896\n",
      "Dict(:fMacro=>0.344779,:fMicro=>0.690856,:fMicroT=>0.467817,:fMacroT=>0.234581)\n",
      "4\n",
      "avg lgth: 24.223747426218257\n",
      "0.6461168935148118\n",
      "0.4398833290824214\n",
      "Dict(:fMacro=>0.266763,:fMicro=>0.697435,:fMicroT=>0.469305,:fMacroT=>0.180703)\n",
      "5\n",
      "avg lgth: 24.22031571722718\n",
      "0.6405124099279423\n",
      "0.4381801643999546\n",
      "Dict(:fMacro=>0.2633,:fMicro=>0.685469,:fMicroT=>0.464226,:fMacroT=>0.180261)\n",
      "6\n",
      "avg lgth: 24.21551132463967\n",
      "0.6541232986389112\n",
      "0.4518347441189745\n",
      "Dict(:fMacro=>0.348141,:fMicro=>0.70233,:fMicroT=>0.476916,:fMacroT=>0.237744)\n",
      "7\n",
      "avg lgth: 24.22168840082361\n",
      "0.6461168935148118\n",
      "0.4444031670058702\n",
      "Dict(:fMacro=>0.346764,:fMicro=>0.696982,:fMicroT=>0.471901,:fMacroT=>0.235904)\n",
      "8\n",
      "avg lgth: 24.077899794097462\n",
      "0.6541232986389112\n",
      "0.46344701226438983\n",
      "Dict(:fMacro=>0.350054,:fMicro=>0.707796,:fMicroT=>0.484907,:fMacroT=>0.241738)\n",
      "9\n",
      "avg lgth: 24.225463280713797\n",
      "0.6509207365892714\n",
      "0.44301892254470876\n",
      "Dict(:fMacro=>0.349711,:fMicro=>0.707057,:fMicroT=>0.47427,:fMacroT=>0.235056)\n",
      "10\n",
      "avg lgth: 24.214824982841456\n",
      "0.6461168935148118\n",
      "0.44562513840592394\n",
      "Dict(:fMacro=>0.267642,:fMicro=>0.698873,:fMicroT=>0.473162,:fMacroT=>0.183156)\n",
      "11\n",
      "avg lgth: 24.22614962251201\n",
      "0.6429143314651722\n",
      "0.43801765723701447\n",
      "Dict(:fMacro=>0.345239,:fMicro=>0.692048,:fMicroT=>0.467162,:fMacroT=>0.233958)\n",
      "12\n",
      "avg lgth: 24.22649279341112\n",
      "0.6469175340272217\n",
      "0.442357911373662\n",
      "Dict(:fMacro=>0.265995,:fMicro=>0.695544,:fMicroT=>0.469493,:fMacroT=>0.181129)\n",
      "13\n",
      "avg lgth: 24.21757035003432\n",
      "0.6549239391513211\n",
      "0.4538280678431539\n",
      "Dict(:fMacro=>0.402787,:fMicro=>0.70492,:fMicroT=>0.478643,:fMacroT=>0.274174)\n",
      "14\n",
      "avg lgth: 24.22031571722718\n",
      "0.6517213771016813\n",
      "0.4547300129154617\n",
      "Dict(:fMacro=>0.325555,:fMicro=>0.707796,:fMicroT=>0.48056,:fMacroT=>0.222686)\n",
      "15\n",
      "avg lgth: 24.204186684969116\n",
      "0.6421136909527622\n",
      "0.4403250371247985\n",
      "Dict(:fMacro=>0.264726,:fMicro=>0.689704,:fMicroT=>0.467049,:fMacroT=>0.181212)\n",
      "16\n",
      "avg lgth: 24.220658888126287\n",
      "0.6565252201761409\n",
      "0.4553448542112077\n",
      "Dict(:fMacro=>0.349652,:fMicro=>0.707264,:fMicroT=>0.480205,:fMacroT=>0.238751)\n",
      "17\n",
      "avg lgth: 24.211736444749484\n",
      "0.6525220176140912\n",
      "0.45207874332232184\n",
      "Dict(:fMacro=>0.321342,:fMicro=>0.701877,:fMicroT=>0.476614,:fMacroT=>0.219878)\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/jair/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg lgth: 24.21551132463967\n",
      "0.6461168935148118\n",
      "0.4444740847725226\n",
      "Dict(:fMacro=>0.400901,:fMicro=>0.697927,:fMicroT=>0.472531,:fMacroT=>0.271996)\n",
      "19\n",
      "avg lgth: 24.217913520933426\n",
      "0.6501200960768615\n",
      "0.4466398456897544\n",
      "Dict(:fMacro=>0.347071,:fMicro=>0.698588,:fMicroT=>0.472971,:fMacroT=>0.236109)\n",
      "20\n",
      "avg lgth: 24.212079615648594\n",
      "0.6477181745396317\n",
      "0.44843304236746867\n",
      "Dict(:fMacro=>0.267017,:fMicro=>0.697681,:fMicroT=>0.473816,:fMacroT=>0.183661)\n",
      "21\n",
      "avg lgth: 24.040150995195606\n",
      "0.6525220176140912\n",
      "0.4430965092055758\n",
      "Dict(:fMacro=>0.269401,:fMicro=>0.707511,:fMicroT=>0.474572,:fMacroT=>0.181516)\n",
      "22\n",
      "avg lgth: 24.221345229924502\n",
      "0.6453162530024019\n",
      "0.4378874691440549\n",
      "Dict(:fMacro=>0.26587,:fMicro=>0.694845,:fMicroT=>0.467578,:fMacroT=>0.180108)\n",
      "23\n",
      "avg lgth: 24.01372683596431\n",
      "0.6405124099279423\n",
      "0.43855707232753255\n",
      "Dict(:fMacro=>0.264084,:fMicro=>0.68736,:fMicroT=>0.465486,:fMacroT=>0.180784)\n",
      "24\n",
      "avg lgth: 24.218943033630747\n",
      "0.6405124099279423\n",
      "0.43036840187246184\n",
      "Dict(:fMacro=>0.264072,:fMicro=>0.688512,:fMicroT=>0.461907,:fMacroT=>0.177964)\n",
      "25\n",
      "avg lgth: 24.21551132463967\n",
      "0.6477181745396317\n",
      "0.4389885067851169\n",
      "Dict(:fMacro=>0.34656,:fMicro=>0.696943,:fMicroT=>0.468976,:fMacroT=>0.233901)\n",
      "scores: 0.6477822257806244\n",
      "f1: 0.4448347173754811\n",
      "Macro: 0.31718958356932625\n",
      "Micro: 0.6978381486934118\n"
     ]
    }
   ],
   "source": [
    "#==================================\n",
    "    Test SDRs + choose best model\n",
    "==================================#\n",
    "\n",
    "\n",
    "classes = unique(map(w -> w, dfTrain[:Stance]))\n",
    "classes = Dict([classes[i] => i-1 for i = 1:length(classes)])\n",
    "dic = StatsBase.countmap(map(w -> w, dfTrain[:Stance]))\n",
    "\n",
    "#===\n",
    "my_clf = E.RandomForestClassifier(n_estimators=500) LM.LogisticRegression() E.RandomForestClassifier()\n",
    "my_clf[:set_params](class_weight=Dict([classes[d[1]] => size(dfTrain[:Stance], 1) / d[2]\n",
    "                                      for d in collect(dic)]))\n",
    "===#\n",
    "\n",
    "my_clf = NB.BernoulliNB()\n",
    "\n",
    "\n",
    "dicTestSDR = Dict()\n",
    "scoresF1, scores, f1Micro, f1Macro = [], [], [], []\n",
    "for i=1:25\n",
    "    \n",
    "    dicSDRs = Dict()\n",
    "    \n",
    "    println(i)\n",
    "    #=== VALIDATION Tests\n",
    "    randIdces = rand(1:size(dfTrain, 1), size(dfTrain, 1))\n",
    "    dataRandIdces = map(i -> dfTrain[i, 1:end], randIdces)\n",
    "\n",
    "    yTrain = map(c -> classes[c[:Stance]], dataRandIdces[1:end-500])\n",
    "    xTrain = map(d -> dataRow2SDR(d), dataRandIdces[1:end-500])\n",
    "    yTest = map(c -> classes[c[:Stance]], dataRandIdces[end-500:end])\n",
    "    xTest = map(d -> dataRow2SDR(d), dataRandIdces[end-500:end]);\n",
    "    ===#\n",
    "    #===#\n",
    "    yTrain = map(c -> classes[c], dfTrain[:Stance])\n",
    "    xTrain = [dataRow2SDR(dfTrain[i, 1:end]) for i =1:size(dfTrain, 1)]\n",
    "    yTest = map(c -> classes[c], dfTest[:Stance])\n",
    "    xTest = [dataRow2SDR(dfTest[i, 1:end]) for i =1:size(dfTest, 1)]\n",
    "    #===#\n",
    "    vv = map(x -> sparse2Dense(x), xTrain) #map(i -> sparse2Dense(xTrain[i]), 1:size(xTrain)[1])\n",
    "    println(\"avg lgth: \", sum(map(v -> sum(v), vv)) / length(vv))\n",
    "    my_clf[:fit](vv, yTrain) \n",
    "    vv = map(i -> sparse2Dense(xTest[i]), 1:size(xTest)[1])\n",
    "    y = my_clf[:predict](vv)\n",
    "    score = sum(map(i -> y[i] == yTest[i], 1:length(y))) / length(y)\n",
    "    append!(scores, score)\n",
    "    println(score)\n",
    "    f1 = METRICS.f1_score(yTest, y, average=\"macro\")\n",
    "    append!(scoresF1, f1)\n",
    "    println(f1)\n",
    "    f1Dict = getF1Scores(yTest, y)\n",
    "    println(f1Dict)\n",
    "    append!(f1Micro, f1Dict[:fMicro])\n",
    "    append!(f1Macro, f1Dict[:fMacro])\n",
    "    dicTestSDR[i] = dicSDRs\n",
    "end\n",
    "\n",
    "\n",
    "println(\"scores: \", sum(scores) / length(scores))\n",
    "println(\"f1: \", sum(scoresF1) / length(scoresF1))\n",
    "println(\"Macro: \", sum(f1Macro) / length(scores))\n",
    "println(\"Micro: \", sum(f1Micro) / length(scoresF1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    BEST SCORE AND SDR MODEL\n",
    "\n",
    "\n",
    "#### MY BEST SCORE for A (with a very simple model):\n",
    "\n",
    "#### precision: = 0.6565252201761409\n",
    "#### F1: 0.4553448542112077\n",
    "#### F-microT and F-macroT as specified in : \"A dataset for detecting stances in Tweets\" (Mohammad, Kirichenko, ...)\n",
    "#### fMicro=>0.707264\n",
    "#### fMacro=>0.349652\n",
    "\n",
    "#### Dict(:fMacro=>0.349652,:fMicro=>0.707264,:fMicroT=>0.480205,:fMacroT=>0.238751)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
